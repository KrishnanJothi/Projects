{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from itertools import product\n",
    "from pandas import read_excel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Number of pairs\n",
    "dataset_size = 7000 \n",
    "\n",
    "\n",
    "# Give the location of the files\n",
    "directory = 'datasets_labeled/'\n",
    "\n",
    "loc_generated_devset = ('datasets/dev_set.csv')\n",
    "loc_generated_trainset = ('datasets/train_set.csv')\n",
    "loc_generated_testset = ('datasets/test_set.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_all_pairs_from_file(directory, filename):\n",
    "    term = filename.split('.')[0]\n",
    "    df_rawgroups = read_excel(directory + filename, sheet_name=\"groups\", index_col=None, header=None, engine='openpyxl')\n",
    "    df_rawgroups = df_rawgroups.drop(df_rawgroups.columns[[0, 1]], axis=1)  # removing first and third unwanted column\n",
    "    df_rawgroups = df_rawgroups.drop([0, 1])  # removing first and third unwanted column\n",
    "\n",
    "    df_group_similarities = read_excel(directory + filename, sheet_name=\"group similarities\", index_col=None, header=None, engine='openpyxl')\n",
    "    df_group_similarities = df_group_similarities.drop(0, axis=0)\n",
    "    df_group_similarities = df_group_similarities.drop(0, axis=1)\n",
    "\n",
    "    df_definition = df_rawgroups[df_rawgroups.columns[range(0, df_rawgroups.shape[1]-1, 4)]]\n",
    "\n",
    "    groups = []\n",
    "    for column in df_definition.columns:\n",
    "        group = []\n",
    "        for definition in df_definition[column]: \n",
    "            if not pd.isna(definition): group.append(definition)\n",
    "        groups.append(group)    \n",
    "        pairs = []\n",
    "\n",
    "    for grp_index1, group1 in enumerate(groups):\n",
    "        for definition1 in group1:\n",
    "            for grp_index2, group2 in enumerate(groups):\n",
    "                for definition2 in group2:\n",
    "                    if definition1 is not definition2:\n",
    "                        sim = df_group_similarities.iloc[grp_index1,grp_index2]\n",
    "                        if type(sim) is str: sim = sim.upper() \n",
    "                        if len(str(sim)) == 1 and (grp_index1 <= grp_index2) and not pd.isna(sim): \n",
    "                            pairs.append([term, term + str(grp_index1), term + str(grp_index2), definition1, definition2, sim])\n",
    "    return pairs\n",
    "\n",
    "pairs = []                  \n",
    "for filename in os.listdir(directory):\n",
    "    if not filename.startswith(\"~\") and filename.endswith(\".xlsx\"):\n",
    "        print(os.path.join(directory, filename))\n",
    "        pairs.extend(get_all_pairs_from_file(directory, filename))\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "df_pairs = pd.DataFrame(pairs, columns=[\"term\", \"grp_id1\", \"grp_id2\", \"definition1\", \"definition2\", \"sim\"])\n",
    "\n",
    "df_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(90*'=')\n",
    "print(\"Datenset zusammenstellen: Möglichst ausgeglichene Anzahl von similarity labels,\\nBenennungen und Begriffsgruppen erstellen\")\n",
    "print(90*'=' + \"\\n\")\n",
    "\n",
    "df = df_pairs.copy(deep=True)\n",
    "df.insert(df.shape[1], \"count_sim\", [0]*df.shape[0], True) \n",
    "df.insert(df.shape[1], \"count_term\", [0]*df.shape[0], True) \n",
    "df.insert(df.shape[1], \"count_grpid1\", [0]*df.shape[0], True) \n",
    "df.insert(df.shape[1], \"count_grpid2\", [0]*df.shape[0], True) \n",
    "df.insert(df.shape[1], \"count_def\", [0]*df.shape[0], True) \n",
    "\n",
    "df_dataset = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "for i in range (0, dataset_size):\n",
    "    #erstes Paar auswählen und entfernen\n",
    "    select = df.iloc[0]\n",
    "    df_dataset = df_dataset.append(select)\n",
    "    df.drop(select.name, inplace=True, errors='raise')\n",
    "    \n",
    "    #eigenschaften hochzählen\n",
    "    df.loc[df.sim == select.sim, 'count_sim'] += 1\n",
    "    df.loc[df.term == select.term, 'count_term'] += 1\n",
    "    df.loc[df.grp_id1 == select.grp_id1, 'count_grpid1'] += 1\n",
    "    df.loc[df.grp_id1 == select.grp_id2, 'count_grpid2'] += 1\n",
    "    df.loc[df.grp_id2 == select.grp_id1, 'count_grpid1'] += 1\n",
    "    df.loc[df.grp_id2 == select.grp_id2, 'count_grpid2'] += 1\n",
    "    df.loc[df.definition1 == select.definition1, 'count_def'] += 1\n",
    "    df.loc[df.definition1 == select.definition2, 'count_def'] += 1\n",
    "    df.loc[df.definition2 == select.definition1, 'count_def'] += 1\n",
    "    df.loc[df.definition2 == select.definition2, 'count_def'] += 1\n",
    "    \n",
    "    #sortieren, so dass Paare mit Eigenschaften, die am seltensten vertreten sind, oben stehen \n",
    "    df.sort_values(by=['count_sim','count_def','count_grpid1','count_grpid2','count_term'], inplace=True)\n",
    "\n",
    "    \n",
    "#Verteilung ausgeben\n",
    "print(df_dataset.groupby(['sim']).size())\n",
    "print('')\n",
    "print(df_dataset.groupby(['term']).size())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Datenset speichern\n",
      "==========================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(90*'=')\n",
    "print(\"Datenset speichern\")\n",
    "print(90*'=' + \"\\n\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "testset_terms = [\"domain\", \"hazard\", \"group\", \"event\"]\n",
    "\n",
    "train_df = df_dataset[~df_dataset[\"term\"].isin(testset_terms)]\n",
    "test_df = df_dataset[df_dataset[\"term\"].isin(testset_terms)]\n",
    "test_df.to_csv(loc_generated_testset)\n",
    "\n",
    "\n",
    "train, dev = train_test_split(train_df, test_size=0.2)\n",
    "train.to_csv(loc_generated_trainset)\n",
    "dev.to_csv(loc_generated_devset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for term in df_dataset[\"term\"].unique():\n",
    "    df_dataset[df_dataset[\"term\"] == term].to_csv(\"datasets_by_term/\"+term+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[train_df[\"term\"]==\"client\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
