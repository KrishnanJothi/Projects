{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from sentence_transformers import SentenceTransformer, LoggingHandler, losses, util, InputExample\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import os\n",
    "import gzip\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "dataset_path = 'from_all_entries_shuffled.tsv'\n",
    "\n",
    "writer_positive_asc = pd.ExcelWriter('sorted_by_diff/positive_asc.xlsx', engine='xlsxwriter')\n",
    "writer_positive_des = pd.ExcelWriter('sorted_by_diff/positive_des.xlsx', engine='xlsxwriter')\n",
    "writer_negative_asc = pd.ExcelWriter('sorted_by_diff/negative_asc.xlsx', engine='xlsxwriter')\n",
    "writer_negative_des = pd.ExcelWriter('sorted_by_diff/negative_des.xlsx', engine='xlsxwriter')\n",
    "writer_all_entries = pd.ExcelWriter('sorted_by_diff/Negative_all_term_diff.xlsx', engine='xlsxwriter')\n",
    "\n",
    "positive_pairs = []\n",
    "negative_pairs = []\n",
    "\n",
    "flag = 1\n",
    "\n",
    "fine_model = SentenceTransformer('fine-tuned_model/fine-tuning-distilroberta-base-paraphrase-v1-2021-05-10_14-17-46')\n",
    "base_model = SentenceTransformer('distilroberta-base-paraphrase-v1')\n",
    "\n",
    "with open(dataset_path, 'rt', encoding='utf8') as fIn:\n",
    "    reader = csv.DictReader(fIn, delimiter='\\t', quoting=csv.QUOTE_NONE)\n",
    "    for row in reader:\n",
    "        \n",
    "        #Compute embedding for both lists\n",
    "        embeddings1 = base_model.encode(row['sentence1'], convert_to_tensor=True)\n",
    "        embeddings2 = base_model.encode(row['sentence2'], convert_to_tensor=True)\n",
    "\n",
    "        #Compute cosine-similarits\n",
    "        cosine_score_base = util.pytorch_cos_sim(embeddings1, embeddings2)\n",
    "\n",
    "        #Compute embedding for both lists\n",
    "        embeddings3 = fine_model.encode(row['sentence1'], convert_to_tensor=True)\n",
    "        embeddings4 = fine_model.encode(row['sentence2'], convert_to_tensor=True)\n",
    "\n",
    "        #Compute cosine-similarits\n",
    "        cosine_score_fine = util.pytorch_cos_sim(embeddings3, embeddings4)\n",
    "\n",
    "        row['Base_model'] = float(cosine_score_base)\n",
    "        row['Fine_model'] = float(cosine_score_fine)\n",
    "        row['difference'] = float(abs(cosine_score_base-cosine_score_fine))\n",
    "        \n",
    "        print(str(round((flag/136392)*100,3))+'% completed')\n",
    "        flag=flag+1\n",
    "                    \n",
    "        if row['score'] == '1.0':    \n",
    "            positive_pairs.append(row)\n",
    "        elif row['score'] == '0.0':\n",
    "            negative_pairs.append(row)\n",
    "                     \n",
    "ascending = pd.DataFrame(negative_pairs).sort_values(by=['difference'])\n",
    "ascending.to_excel(writer_all_entries, sheet_name='Negative_all_pairs_diff',index=False) \n",
    "writer_all_entries.save()\n",
    "\n",
    "'''\n",
    "ascending = ascending.head(5000)\n",
    "descending = pd.DataFrame(positive_pairs).sort_values(by=['difference'], ascending=False)\n",
    "descending = descending.head(5000)\n",
    "ascending.to_excel(writer_positive_asc, sheet_name='Positive_pairs_ascending',index=False) \n",
    "descending.to_excel(writer_positive_des, sheet_name='Positive_pairs_descending',index=False) \n",
    "\n",
    "ascending_ = pd.DataFrame(negative_pairs).sort_values(by=['difference'])\n",
    "ascending_ = ascending_.head(5000)\n",
    "descending_ = pd.DataFrame(negative_pairs).sort_values(by=['difference'], ascending=False)\n",
    "descending_ = descending_.head(5000)\n",
    "ascending_.to_excel(writer_negative_asc, sheet_name='Negative_pairs_ascending',index=False) \n",
    "descending_.to_excel(writer_negative_des, sheet_name='Negative_pairs_descending',index=False) \n",
    "\n",
    "\n",
    "writer_positive_asc.save()\n",
    "writer_positive_des.save()\n",
    "writer_negative_asc.save()\n",
    "writer_negative_des.save()'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_excel('sorted_by_diff/positive_all_term_diff.xlsx')\n",
    "\n",
    "\n",
    "def plot_dist(model):\n",
    "    step = (np.max(model) - np.min(model))/100\n",
    "    bin_values = np.arange(start=np.min(model), stop=np.max(model+step), step=step)\n",
    "    model.hist(bins=bin_values, figsize=[14,6],legend=True)\n",
    "\n",
    "plot_dist(df['Base_model'])\n",
    "plot_dist(df['Fine_model'])\n",
    "\n",
    "plt.figure()\n",
    "plot_dist(df[df['split']=='train']['Fine_model'])\n",
    "plot_dist(df[df['split']=='dev']['Fine_model'])\n",
    "plot_dist(df[df['split']=='test']['Fine_model'])\n",
    "labels= [\"FineModel-Positive Train\",\"FineModel-Positive Dev\", \"FineModel-Positive Test\"]\n",
    "plt.legend(labels)\n",
    "\n",
    "plt.figure()\n",
    "plot_dist(df[df['split']=='train']['Base_model'])\n",
    "plot_dist(df[df['split']=='dev']['Base_model'])\n",
    "plot_dist(df[df['split']=='test']['Base_model'])\n",
    "labels= [\"BaseModel-Positive Train\",\"BaseModel-Positive Dev\", \"BaseModel-Positive Test\"]\n",
    "plt.legend(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
